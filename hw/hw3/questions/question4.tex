\section{Question 4}
\subsection{(a)}
The recursive relationship for the number of deadlines that Xun handles is defined as:
\[
    S(i, D, W) = \begin{cases}
        \sum\limits_{k=i}^{N}d[k]                                                                                 & N - i \le 3D \text{ and } W = \id{Xun} \\
        \min\limits_{1 \le X \le 3D} \{S(i + X + 1, \max(X, D), \id{Xun})\}                                       & W = \id{Yuntao}                        \\
        \max\limits_{1 \le X \le 3D} \{S(i + X + 1, N, \max(X, D), \id{Yuntao}) + \sum\limits_{k=i}^{i + X}d[k]\} & W = \id{Xun}
    \end{cases}
\]


The left-hand side shows a call $S$ being made for some starting day $i$, $D$, and worker $W$ (Xun or Yuntao), where $S$ represents the number of deadlines that Xun will handle from day $i$ to the end.
Firstly is the case when the number of days that remain is less than or equal to $3D$.
Since both Xun and Yuntao choose optimally, they will always take the full remainder if possible.
Therefore, in this case, Xun will simply handle all of the remaining deadlines.

Next is the case when it is Yuntao's turn.
Since he is looking to minimize the number of deadlines that Xun handles, he will iterate through all possible values of $X$ (from 1 to $3D$) and select the one which yields the smallest value.
To produce a value, a recursive call is made where the current day, $i$, has been updated to $i + X + 1$, which would be the starting day for Xun's next turn.

Finally, we can examine the case of Xun's turn.
This case is basically the converse of the one previously described.
Instead of trying to find the minimum value, Xun is trying to find which choice of $X$ (from 1 to $3D$) will maximize the number of deadlines that she handles.
We must also make sure that, for Xun's choice of $X$, the corresponding sum of deadlines from $i$ to $i + X$ will be added to her total.

\subsection{(b)}
The answer to this problem will be shown through a progression of algorithms which output the number of deadlines handled by Xun given optimal choices, from the most time-complex to the least.
For the initial approach to this problem, consider the pseudocode below:
\begin{spacing}{1.2}
    \begin{codebox}
        \Procname{$\proc{Q4b-Worst}(d, i, N, D, \id{Xsum}, \id{Worker})$}
        \li \If $N - i < 3D$
        \Then
        \li \If $\id{Worker} = \id{Xun}$
        \Then
        \li $\id{Xsum} = \id{Xsum} + \proc{Sum}(d, i, N)$
        \End
        \li \Return $\id{Xsum}$
        \End

        \li \If $\id{Worker} = \id{Xun}$
        \Then
        \li $\id{max-deadlines} = -\infty$
        \li \For $\id{X} = 1$ \To $3D$
        \Do
        \li $\id{new-i} = i + \id{X} + 1$
        \li $\id{new-D} = \max(\id{X}, D)$
        \li $\id{new-Xsum} = \id{Xsum} + \proc{Sum}(d, i, \id{X})$
        \li $\id{deadlines} = \proc{Q4b-Worst}(d, \id{new-i}, N, \id{new-D}, \id{new-Xsum}, \id{Yuntao})$
        \li $\id{max-deadlines} = \max(\id{max-deadlines}, \id{deadlines})$
        \End
        \li \Return $\id{max-deadlines}$
        \End

        \li \If $\id{Worker} = \id{Yuntao}$
        \Then
        \li $\id{min-deadlines} = \infty$
        \li \For $\id{X} = 1$ \To $3D$
        \Do
        \li $\id{new-i} = i + \id{X} + 1$
        \li $\id{new-D} = \max(\id{X}, D)$
        \li $\id{deadlines} = \proc{Q4b-Worst}(d, \id{new-i}, N,\id{new-D}, \id{Xsum}, \id{Xun})$
        \li $\id{min-deadlines} = \min(\id{min-deadlines}, \id{deadlines})$
        \End
        \li \Return $\id{min-deadlines}$
        \End
    \end{codebox}
\end{spacing}
\vspace{7mm}
\textbf{Explanation of $\proc{Q4b-Worst}$:}\\
The pseudocode above uses the minimax principle, where one person is trying to maximize some score, and the other is trying to minimize it.
In this case, the score in question is the total number of deadlines handled by Xun, where Xun is also the person who is trying to maximize the score.
The base case in this recursive function is when the remainder of days in the deadline array $d$ is less than or equal to $3D$.
This is because both Xun and Yuntao choose optimally, so if either of them have the chance to take the remainder of the deadlines, then they will.

Initially, this function will be called as:
\begin{center}
    $\proc{Q4b-Worst}(d, 1, N, 1, 0, \id{Xun})$
\end{center}
This passes in the full array of deadlines, sets $D = 1$, the number of Xun's deadlines ($\id{Xsum}$) to 0, and sets Xun as the person currently working.
When Xun is working (lines 5 - 13), each value of $X$, $1 \le X \le 3D$ is tried by calling the function recursively,
now with $i + X + 1$ as the new current day, $D$ set to $\max(X, D)$, the sum of deadlines from $i$ (current day) to $X$ is added to $\id{Xsum}$, and finally the worker is now Yuntao.
Xun's tests return the maximum number of deadlines possible for a certain starting point in the deadline list, given that Yuntao is also making optimal decisions.

When it is Yuntao's turn (lines 14 - 21), he is trying to minimize the number of deadlines handled by Xun.
This part of the algorithm is fundamentally the same as Xun's, however instead of returning a recursive maximum, it returns a recursive minimum.
Also, instead of updating $\id{Xsum}$, it simply is left as how it was passed. This is because Yuntao is \textbf{taking away} $X$ deadlines from Xun,
not adding them. \\


\textbf{Analysis of $\proc{Q4b-Worst}$:}\\
There are two main reasons why this algorithm is the ``worst''.
First, each time that a sum is computed, the array of deadlines must be iterated through:

\begin{spacing}{1.2}
    \begin{codebox}
        \Procname{$\proc{Sum}(d, i, j)$}
        \li $\id{sum} = 0$
        \li \For $x = i$ \To j
        \Do
        \li $\id{sum} = \id{sum} + d[x]$
        \End
        \li \Return $\id{sum}$
    \end{codebox}
\end{spacing}
\vspace{5mm}
Asymptotically, the $\proc{Sum}$ function is $\mathcal{O}(n)$ in time since the distance between $i$ and $j$ is only bounded by the size of $d$.

The second reason why $\proc{Q4b-Worst}$ is poor is because of the number of recursive calls that it makes.
There is nothing stopping the algorithm from calculating a certain configuration of the worker, $D$, and current day that it already has in the past.
This is, of course, a classic example of where dynamic programming can help optimize an algorithm.

The time complexity of this algorithm can be shown through the expression:
\[T(n) = \sum_{X = 1}^{n-1}(T(n - X) + X)\]
Each value of $X$ that can be chosen is iterated through (with an upper bound of $n$ being placed on $X$), and a recursive call is made on what remains in the deadline array.
The value of $X$ is also added for each call, since this is the amount of time that the $\proc{Sum}$ function will take.
We can rearrange the expression to achieve:
\[T(n) = \sum_{X = 1}^{n-1}T(n - X) + \sum_{X = 1}^{n-1}X = \sum_{X = 0}^{n-1}T(X) + \mathcal{O}(n^2)\]
The following upper bound can be placed on this expression (CLRS, 3rd Edition, pg. 364):
\[T(n) = \mathcal{O}({n^2}{2^n})\]
In terms of space, at any given point the number of recursive calls that will be stored will be bounded by the depth of the recursive tree.
The maximum depth of the recursive tree occurs when each call removes a minimum amount of the deadline array.
Since the minimum amount of the array that can be removed is 1, then the maximum depth of this tree is bounded by $\mathcal{O}(n)$.
Therefore, since each call uses a constant amount of memory, this algorithm is $\mathcal{O}(n)$ in space. \\

\textbf{Introducing dynamic programming:}\\
The aforementioned issues can be mitigated through the use of dynamic programming.
To begin, we can use a bottom-up approach to store the sum of each possible sub-array for $\mathcal{O}(1)$ use in the $\proc{Q4b}$ algorithm.

\begin{spacing}{1.2}
    \begin{codebox}
        \Procname{$\proc{BottomUpSums}(d, N)$}
        \li Let $s$ by an $N \times N$ array of zeros

        \li \For $i = 1$ \To $N$
        \Do
        \li $s[i, i] = d[i]$
        \End

        \li \For $l = 2$ \To $N$
        \Do
        \li \For $i = 1$ \To $N - l + 1$
        \Do
        \li $j = i + l - 1$
        \li $s[i, j] = s[i, j - 1] + s[j, j]$
        \End
        \End
        \li \Return $s$
    \end{codebox}
\end{spacing}
\vspace{5mm}
In the algorithm above, lines 2 and 3 first find the sums of the smallest possible sub-arrays, which are single indices.
From there, the \textbf{for} loop at line 4 specifies the size of the next sub-arrays whose sums will be calculated.
For the corresponding size, $l$, the nested \textbf{for} loop (lines 5 - 7) finds two values in $s$ which will directly add up to the correct sum.
For example, it will calculate the sum of a sub-array from indices $i$ to $j$, by adding the sums of the sub-arrays from $i$ to $j - 1$ and $j$ to $j$.
Since the sub-arrays are calculated in increasing order of length (line 4) there will have already been sums stored for the sub-arrays from $i$ to $j - 1$ and $j$ to $j$.
Since there are $\binom{N}{2}$ total sub-arrays, the space complexity of this algorithm is $\mathcal{O}(n^2)$.
In terms of time, the bottom-up approach allows this algorithm to be $\mathcal{O}(n^2)$ as well, since each $s[i, j]$ takes $\mathcal{O}(1)$ to calculate.

Next, we can address the issue of how many recursive calls are made.
The dynamic programming approach that will be used is top-down, or ``memoization''.
Since Xun and Yuntao are choosing optimally, we can store the outcome (number of deadlines handled by Xun) of each sub-array that traverses from some day $i$ to the end individually.
Therefore, a structure that we can use to store such data is a hash table, where the key is a tuple of three values ($\id{Worker}$, $D$, $i$), and the value is the outcome given the respective configuration.
This tuple contains $i$, the starting point of the remainder of the array after some set of deadlines are chosen, the corresponding $D$ value, and the worker (Xun or Yuntao) whose turn is next.

This addition greatly reduces the number of recursive calls that are made.
In short, there is one sub-array that spans some index $i$ to the end of the full array, and a total of $N$ possible values of $i$.
Letting $k$ represent the number of possible values $D$ may take, the total number of recursive calls that needs to be made is $2\mathcal{O}(kn)$ (the coefficient represents two players).
However, since the value of $D$ is only bounded by $n$, we can express the new total number of recursive calls as $2\mathcal{O}(n^2) = \mathcal{O}(n^2)$.

Consider the pseudocode below:

\begin{spacing}{1.2}
    \begin{codebox}
        \Procname{$\proc{InitMemo}(N)$}
        \li Let $m$ be a hash table that takes keys of three-integer tuples
        \li \For $D = 1$ \To $N$
        \Do
        \li \For $i = 1$ \To $N$
        \Do
        \li $m[(\id{Xun}, D, i)] = -1$
        \li $m[(\id{Yuntao}, D, i)] = -1$
        \End
        \End
        \li \Return $m$
    \end{codebox}
\end{spacing}
\vspace{5mm}

The above pseudocode shows how the hash table used to memoize the tuples would be initialized, with each unseen configuration set to -1.

We must also consider the space requirements of this incorporation. Since we are storing a single integer for $2n^2$ possible pairs, the space complexity of this structure is $\mathcal{O}(n^2)$. \\

\textbf{Creating an optimized algorithm: }\\
Finally, let us imagine some algorithm $\proc{Q4b-Better}$ which uses the same recursive principles described in $\proc{Q4b-Worst}$, but incorporates the bottom-up and top-down optimizations previously described.
To reiterate, this algorithm will obtain sums of sub-arrays from a pre-calculated table in $\mathcal{O}(1)$ time and memoize sub-arrays based on the starting day, value of $D$, and starting worker (Xun or Yuntao).
This second optimization will limit the number of recursive calls made to just $\mathcal{O}(n^2)$.
To show this, we can examine each dimension of the memoization keys.
The first is the starting day of the sub-array; since there are only $N$ possible starting days, this dimension has a maximum size of $N$.
Next is the value of $D$.
Since $D$ is proportional to whatever value of $X$ is chosen, and the maximum possible value of $X$ is $N$, $D$ is also limited by $N$, and therefore its dimension also has a maximum size of $N$.
Finally the last dimension is just the player, therefore it has a maximum size of 2.
Therefore, the maximum number of recursive calls that can be made is bounded by $2 \times N \times N = \mathcal{O}(n^2)$. \\

\textbf{Analysis of the optimized algorithm:}\\
To analyze the full optimized approach to this problem, we must analyze the union of $\proc{BottomUpSums}$, $\proc{InitMemo}$, and $\proc{Q4b-Better}$.
As stated previously, the tabulation of the sums of all sub-arrays within the array of deadlines is calculated by the $\proc{BottomUpSums}$ algorithm in both $\mathcal{O}(n^2)$ time and space.
Next, the initialization of the memoization table is facilitated by the $\proc{InitMemo}$ function.
As also stated previously, this function stores an integer value for each combination of indices of the deadline array (bounded by $N$) and possible values of $D$ (also bounded by $N$).
Therefore, this function is also bounded by $\mathcal{O}(n^2)$ in time and space.
Finally, we come to our $\proc{Q4b-Better}$ algorithm.
We now must analyze the time complexity of an individual recursive call.
Each recursive call can find the sum of a given subarray in $\mathcal{O}(1)$ time, with this action being performed once per iteration through the possible choices of $X$.
The number of choices of $X$ is bounded by $N$, the size of the full deadline array, so each recursive call has an $\mathcal{O}(n)$ upper bound.
Also, because the amount of data stored with each recursive call is independent of input size, each recursive call is individually $\mathcal{O}(1)$ in space.
Therefore, since the use of memoization limits the number of recursive calls made to $\mathcal{O}(n^2)$, $\proc{Q4b-Better}$ is $\mathcal{O}(n^3)$ in time and $\mathcal{O}(n)$ in space for the same reason as described with the un-optimzed algorithm.

Finally, the total time complexity of the dynamic approach can be expressed as:
\[\mathcal{O}(n^2) + \mathcal{O}(n^2) + \mathcal{O}(n^3) = 2\mathcal{O}(n^2) + \mathcal{O}(n^3) = \mathcal{O}(n^3)\]

And the space complexity is shown to be:
\[\mathcal{O}(n^2) + \mathcal{O}(n^2) + \mathcal{O}(n) = 2\mathcal{O}(n^2) + \mathcal{O}(n) = \mathcal{O}(n^2)\]

\textbf{Getting a final answer:}\\
Finally, since the $\proc{Q4b-Better}$ algorithm only gives us the number of deadlines that Xun handles, we can find who handles the most deadlines by the same principle used in the last sentence of the previous section.
Therefore, consider the pseudocode below:

\begin{spacing}{1.2}
    \begin{codebox}
        \Procname{$\proc{Q4b-FinalAnswer}(d, N)$}
        \li $s = \proc{BottomUpSums}(d, N)$
        \li $m = \proc{InitMemo}(N)$
        \li $\id{deadlines-Xun} = \proc{Q4b-Better}(d, i, N, D, 0, \id{Xun}, s, m)$
        \li \If $\id{deadlines-Xun} > {1 \over 2}s[1, N]$
        \Then
        \li \Return $\id{Xun}$
        \li \ElseIf $\id{deadlines-Xun} < {1 \over 2}s[1, N]$
        \Then
        \li \Return $\id{Yuntao}$
        \li \Else
        \li \Return $\id{Tie}$
        \End
    \end{codebox}
\end{spacing}
\vspace{5mm}
If the number of deadlines that Xun handles is greater than half of the total deadlines, then she handles the most.
Otherwise if it is less, then Yuntao does.
Finally, if the number of deadlines handled by each worker is equal, then it is a tie.\\

\textbf{Summary:}\\
In the solution to this question, we first examined the baseline minimax implementation of the Xun and Yuntao's strategies, $\proc{Q4b-Worst}$.
Then, we introduced dynamic programming to greatly decrease the original algorithm's time complexity.
This was done in two steps:
\begin{spacing}{1}
    \begin{itemize}
        \item A bottom-up approach for summing sub-arrays
        \item A top-down (memoization) approach for storing the output of deadlines completed by Xun within a certain sub-array
    \end{itemize}
\end{spacing}

The first optimization in $\proc{Q4b-Better}$ allowed for an $\mathcal{O}(1)$ retrieval of sums instead of $\mathcal{O}(n)$, and the second optimization limited the number of recursive calls that needed to be made to $\mathcal{O}(n^2)$.
Finally, through an analysis of the full process, it was found that the time complexity was reduced from $\mathcal{O}({n^2}{2^n})$ to $\mathcal{O}(n^3)$, with the space complexity increasing from $\mathcal{O}(n)$ to $\mathcal{O}(n^2)$.